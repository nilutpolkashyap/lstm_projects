{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop LSTM Models For Univariate Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing independent and dependent features\n",
    "def prepare_data(timeseries_data, n_features):\n",
    "    X, y =[],[]\n",
    "    for i in range(len(timeseries_data)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_features\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(timeseries_data)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input sequence\n",
    "timeseries_data = [110, 125, 133, 146, 158, 172, 187, 196, 210]\n",
    "# choose a number of time steps\n",
    "n_steps = 3\n",
    "# split into samples\n",
    "X, y = prepare_data(timeseries_data, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[110 125 133]\n",
      " [125 133 146]\n",
      " [133 146 158]\n",
      " [146 158 172]\n",
      " [158 172 187]\n",
      " [172 187 196]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146 158 172 187 196 210]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 6s 6s/step - loss: 33160.1992\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 32556.1348\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 32111.1562\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 31717.4668\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 31335.9824\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 30941.2402\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 30516.7812\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 30065.5566\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 29610.7480\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 29184.0781\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 28735.5254\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 28276.7500\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 27822.2676\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 27372.3965\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 26924.8340\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 26476.7598\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 26012.9141\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 25521.3184\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 24998.0527\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 24425.8496\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 23772.1719\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 22972.7734\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 21908.4160\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 20438.7695\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18654.9180\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 16924.6699\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 15423.4717\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 14044.9873\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 12834.9844\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 11752.0889\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 156ms/step - loss: 10654.5342\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 9538.1396\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 8402.8936\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 7255.6211\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 6103.9253\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 4969.7485\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 3876.9648\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2829.8633\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 1917.1641\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 1197.6348\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 666.5930\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 301.7206\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 89.5472\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 22.0612\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 89.8185\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 245.1584\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 436.9044\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 616.7919\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 754.7141\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 838.6662\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 863.0947\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 830.0965\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 751.0731\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 641.5203\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 516.9939\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 391.9445\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 277.687 - 0s 169ms/step - loss: 277.6873\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 181.8426\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 108.4093\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 58.2438\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 29.7600\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 19.6921\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 23.8276\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 37.6365\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 56.7003\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 76.4637\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 94.5063\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 108.9096\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 118.4398\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 122.5810\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 121.4278\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 115.5627\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 105.9136\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 93.6191\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 79.8985\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 65.9338\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 52.7751\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 41.2647\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 31.9894\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 25.2594\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 21.1124\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 19.3446\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 19.5610\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 21.2387\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 23.7976\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 26.6696\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 29.3567\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 31.4752\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 32.7804\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 33.1714\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 32.6787\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 31.4379\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 29.6545\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 27.5676\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 25.4145\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 23.4030\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 21.6918\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 20.3797\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 19.5056\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 19.0538\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 18.9658\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 19.1545\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 19.5197\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 19.9610\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 20.3896\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 20.7367\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 20.9566\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 21.0288\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 20.9551\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 20.7558\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 20.4634\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 20.1175\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 19.7578\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 19.4200\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 19.1317\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 164ms/step - loss: 18.9103\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 18.7630\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 18.6869\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 18.6717\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 18.7019\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 18.7592\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 18.8242\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 18.8800\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 18.9153\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 18.9240\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 18.9049\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 18.8611\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 18.7987\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 18.7245\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 18.6467\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 18.5720\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 18.5061\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 18.4523\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 159ms/step - loss: 18.4119\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 18.3843\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 150ms/step - loss: 18.3673\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 18.3577\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.3520\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.3466\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.3390\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 18.3270\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 18.3097\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 18.2870\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 18.2598\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.2291\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.1968\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.1641\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 18.1326\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 18.1032\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 18.0766\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 18.0524\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 18.0303\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 18.0094\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 17.9886\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 17.9672\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 17.9446\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 17.9205\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 17.8949\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 17.8676\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 17.8384\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 17.8075\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 17.7745\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 17.7391\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 17.7003\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 17.6571\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 17.6070\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 17.5460\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 17.4673\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 17.3585\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 17.1967\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 16.9398\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 16.5165\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 15.8353\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 14.9766\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 15.9582\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 14.5744\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 14.0731\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 14.1236\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 14.1369\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 13.9131\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 13.3566\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 12.4757\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 11.7530\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 12.2004\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 11.2612\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10.5073\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 10.5203\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 10.2349\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 9.3947\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 8.8042\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 8.9893\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 7.9828\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.7702\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 7.6415\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 6.9365\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.7497\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 6.5955\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.0667\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 6.1702\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.8007\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 5.6925\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 5.6971\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 5.4545\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 5.6149\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 5.3868\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 5.5465\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.4081\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 5.4777\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 5.4847\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 5.4205\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 5.5128\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 5.4070\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 5.4933\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 5.3855\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 5.4438\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 5.3559\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 5.3673\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 5.3261\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 157ms/step - loss: 5.2832\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 5.2785\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 5.2142\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 5.2212\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 5.1579\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.1604\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 5.1156\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.1018\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.0832\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 5.0529\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 5.0514\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 5.0184\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 5.0178\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 4.9940\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 4.9850\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 4.9730\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.9559\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 4.9508\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.9309\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 4.9258\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 4.9087\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 4.8987\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 4.8864\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.8714\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 4.8620\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 4.8451\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 4.8353\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 4.8192\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 4.8074\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.7931\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.7790\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 4.7663\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.7510\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.7389\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.7235\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.7112\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.6964\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.6834\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 4.6694\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 4.6558\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.6424\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.6284\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 4.6154\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 4.6013\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 4.5883\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 4.5743\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 4.5613\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 151ms/step - loss: 4.5474\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 4.5342\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 4.5204\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 4.5071\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 166ms/step - loss: 4.4935\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 4.4801\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.4666\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 4.4531\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 4.4397\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 4.4262\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 4.4129\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 170ms/step - loss: 4.3994\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 4.3861\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 4.3727\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 4.3595\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 4.3461\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 4.3330\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 167ms/step - loss: 4.3197\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 4.3066\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.2935\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 4.2804\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 4.2673\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 4.2542\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 4.2411\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 4.2280\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.2148\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.2016\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1882\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 4.1747\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.1612\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.1478\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.1349\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 4.1226\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 4.1099\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.0944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2373179fbc8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X, y, epochs=300, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting For the next 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[225.93896]\n",
      "1 day input [196.      210.      225.93896]\n",
      "1 day output [[238.16043]]\n",
      "2 day input [210.      225.93896 238.16043]\n",
      "2 day output [[253.91147]]\n",
      "3 day input [225.93896 238.16043 253.91147]\n",
      "3 day output [[270.12515]]\n",
      "4 day input [238.16043 253.91147 270.12515]\n",
      "4 day output [[285.36917]]\n",
      "5 day input [253.91147 270.12515 285.36917]\n",
      "5 day output [[302.99982]]\n",
      "6 day input [270.12515 285.36917 302.99982]\n",
      "6 day output [[320.98123]]\n",
      "7 day input [285.36917 302.99982 320.98123]\n",
      "7 day output [[339.3026]]\n",
      "8 day input [302.99982 320.98123 339.3026 ]\n",
      "8 day output [[359.4026]]\n",
      "9 day input [320.98123 339.3026  359.4026 ]\n",
      "9 day output [[380.15198]]\n",
      "[225.93896, 238.16043, 253.91147, 270.12515, 285.36917, 302.99982, 320.98123, 339.3026, 359.4026, 380.15198]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction for next 10 days\n",
    "x_input = np.asarray([187, 196, 210]).astype('float32')\n",
    "temp_input=list(x_input)\n",
    "lst_output=[]\n",
    "i=0\n",
    "while(i<10):\n",
    "    \n",
    "    if(len(temp_input)>3):\n",
    "        x_input=np.asarray(temp_input[1:]).astype('float32')\n",
    "        print(\"{} day input {}\".format(i,x_input))\n",
    "        #print(x_input)\n",
    "        x_input = x_input.reshape((1, n_steps, n_features))\n",
    "        #print(x_input)\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(\"{} day output {}\".format(i,yhat))\n",
    "        temp_input.append(yhat[0][0])\n",
    "        temp_input=temp_input[1:]\n",
    "        #print(temp_input)\n",
    "        lst_output.append(yhat[0][0])\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, n_steps, n_features))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(yhat[0])\n",
    "        temp_input.append(yhat[0][0])\n",
    "        lst_output.append(yhat[0][0])\n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "print(lst_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[110, 125, 133, 146, 158, 172, 187, 196, 210]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeseries_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timeseries_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[225.93896,\n",
       " 238.16043,\n",
       " 253.91147,\n",
       " 270.12515,\n",
       " 285.36917,\n",
       " 302.99982,\n",
       " 320.98123,\n",
       " 339.3026,\n",
       " 359.4026,\n",
       " 380.15198]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaing The Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_new=np.arange(1,10)\n",
    "day_pred=np.arange(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2375bc7fd48>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(day_new,timeseries_data)\n",
    "plt.plot(day_pred,lst_output)\n",
    "plt.legend(['training_values','predicted_values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.5'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
